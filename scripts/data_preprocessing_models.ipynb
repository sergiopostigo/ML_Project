{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **Agricultural Exports Categories Analysis**\n",
    "*by Sergio Postigo and Víctor Diví*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## **5. Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this stage we will preprocess the data to be used in a classification model. As seen in the Data Exploration section, there is a big class inbalance. We will adress this issue as first step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/cleaned_data/cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will use down-sampling to reduce the number of instances of the more popular categories. For each category we will have at most 20.000 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Palta        20000\n",
       "Mandarina    20000\n",
       "Uva          20000\n",
       "Quinua       20000\n",
       "Arándano     20000\n",
       "Café         20000\n",
       "Cebolla      20000\n",
       "Espárrago    20000\n",
       "Flores       20000\n",
       "Granada      12672\n",
       "Maíz         11946\n",
       "Ají           7814\n",
       "Paprika       7178\n",
       "Arveja        6140\n",
       "Orégano       4997\n",
       "Frejol        4993\n",
       "Aceituna      4890\n",
       "Fresa         3975\n",
       "Tomate        3151\n",
       "Papa          2699\n",
       "Ajo           2228\n",
       "Zapallo       2117\n",
       "Alcachofa     1553\n",
       "Arroz         1308\n",
       "Trigo          957\n",
       "Tuna           317\n",
       "Avena          308\n",
       "Alfalfa         73\n",
       "Zanahoria       51\n",
       "Frambuesa       22\n",
       "Azúcar          22\n",
       "Brócoli         10\n",
       "Haba             2\n",
       "Vid              2\n",
       "Name: Categoría macro Aurum, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_per_group = {name: min(count, 20000) for name, count in data['Categoría macro Aurum'].value_counts().items()}\n",
    "data = data.groupby('Categoría macro Aurum').apply(\n",
    "    lambda group: group.sample(samples_per_group[group.name], random_state=5)).reset_index(drop=True)\n",
    "data['Categoría macro Aurum'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Convert the resample dataset into a dataframe and persist locally it for easy future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"../data/preprocessed_data/resampled_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Until now, we have worked over the whole dataset, since the actions performed would be also done over new data. However, the next steps should only be performed with the training data, so we will split the data into two sets (80-20), and carry on working with only the 80% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=5)\n",
    "train.to_csv('../data/preprocessed_data/train_data.csv', index=False)\n",
    "test.to_csv('../data/preprocessed_data/test_data.csv', index=False)\n",
    "data = train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We are dealing with text, categorical and numerical data in this dataset. The next step will be then to represent the text columns as numbers, which is known as *sentence embedding*. This will be done in the columns *Descripcion de la Partida Aduanera* and *Descripcion Comercial*. Let's create a function to convert the text columns into vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "\n",
    "def col2vectors(rows: List[str]) -> Doc2Vec:\n",
    "    model_input = [TaggedDocument(row.split(), [i]) for i, row in enumerate(rows)]\n",
    "\n",
    "    doc2vec_model = Doc2Vec(vector_size=10, min_count=2, epochs=10)\n",
    "    doc2vec_model.build_vocab(model_input)\n",
    "\n",
    "    doc2vec_model.train(model_input, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "\n",
    "    return doc2vec_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Convert *Descripcion de la Partida Aduanera (description of the customs code)* and save locally for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = col2vectors(data[\"Descripcion de la Partida Aduanera\"].values)\n",
    "model.save(\"../models/custom_descriptions_doc2vec_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's do the same for *Descripcion Comercial (comercial description)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = col2vectors(data[\"Descripcion Comercial\"].values)\n",
    "model.save(\"../models/comercial_descriptions_doc2vec_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('ml_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7741a1131fbe9bf5a0f5d7457e8f9d1e7d381e789d9a050b2713f6d313501fbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
